{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b1158576",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.data import InMemoryDataset\n",
    "from torch_geometric.data import Dataset\n",
    "import pandas as pd\n",
    "\n",
    "import statistics\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import random\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "from torch_geometric.data import InMemoryDataset\n",
    "from tqdm import tqdm\n",
    "from torch_geometric.data import Dataset\n",
    "# from torch.utils.data import DataLoader\n",
    "from torch_geometric.data import DataLoader\n",
    "\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "from torch_geometric.nn import GCNConv\n",
    "from torch_geometric.nn import GATConv\n",
    "import sklearn\n",
    "from segment_anything import SamPredictor, sam_model_registry\n",
    "from math import sqrt\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "import cv2\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2435c3b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import skimage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "17b847a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.checkpoint = \"../../Data_full/SegmentAnything/sam_vit_h_4b8939.pth\"\n",
    "        self.model_type = \"vit_h\"\n",
    "        self.model = sam_model_registry[self.model_type](checkpoint=self.checkpoint)\n",
    "        # self.sam.to(device='cuda')\n",
    "        for param in self.model.image_encoder.parameters():\n",
    "            param.requires_grad = False\n",
    "        self.model = self.model.image_encoder\n",
    "        # self.predictor = SamPredictor(self.sam)\n",
    "\n",
    "    def forward(self, data):\n",
    "        x = self.model(data)\n",
    "        return x\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "model = Encoder().to(device)\n",
    "\n",
    "# img = cv2.imread(r'test.png')\n",
    "# result = model(img)\n",
    "# print(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8bf7cab7",
   "metadata": {},
   "outputs": [],
   "source": [
    "x=torch.randn(1,3,1024,1024).to(device)\n",
    "res=model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "a82240dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "18c7d1a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([   \n",
    "        transforms.ToTensor(),\n",
    "        transforms.Resize((1024, 1024)),\n",
    "        transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "f08dc9c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "im = cv2.imread(r'../test.png')\n",
    "im = cv2.cvtColor(im, cv2.COLOR_BGR2RGB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "69a3c554",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_im = transform(im)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "6e892c8c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 1024, 1024])"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_im.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2ecfc5c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "13a47552",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_im = new_im[None, :].to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "94ac78c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 3, 1024, 1024])"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_im.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "ad5b85ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = model(new_im)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "c74a0d71",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[-0.0308, -0.0618, -0.0618,  ..., -0.0618, -0.0618, -0.0506],\n",
       "          [-0.0600, -0.0901, -0.0901,  ..., -0.0901, -0.0901, -0.0839],\n",
       "          [-0.0600, -0.0901, -0.0901,  ..., -0.0901, -0.0901, -0.0839],\n",
       "          ...,\n",
       "          [-0.0600, -0.0901, -0.0901,  ..., -0.0901, -0.0901, -0.0839],\n",
       "          [-0.0600, -0.0901, -0.0901,  ..., -0.0901, -0.0901, -0.0839],\n",
       "          [ 0.0248,  0.0070,  0.0070,  ...,  0.0070,  0.0070,  0.0110]],\n",
       "\n",
       "         [[ 0.1290,  0.1009,  0.1009,  ...,  0.1009,  0.1009,  0.1262],\n",
       "          [ 0.1341,  0.0887,  0.0887,  ...,  0.0887,  0.0887,  0.1050],\n",
       "          [ 0.1341,  0.0887,  0.0887,  ...,  0.0887,  0.0887,  0.1050],\n",
       "          ...,\n",
       "          [ 0.1341,  0.0887,  0.0887,  ...,  0.0887,  0.0887,  0.1050],\n",
       "          [ 0.1341,  0.0887,  0.0887,  ...,  0.0887,  0.0887,  0.1050],\n",
       "          [ 0.1954,  0.1528,  0.1528,  ...,  0.1528,  0.1528,  0.1262]],\n",
       "\n",
       "         [[ 0.1185,  0.0731,  0.0731,  ...,  0.0731,  0.0731,  0.1001],\n",
       "          [ 0.1026,  0.0304,  0.0304,  ...,  0.0304,  0.0304,  0.0688],\n",
       "          [ 0.1026,  0.0304,  0.0304,  ...,  0.0304,  0.0304,  0.0688],\n",
       "          ...,\n",
       "          [ 0.1026,  0.0304,  0.0304,  ...,  0.0304,  0.0304,  0.0688],\n",
       "          [ 0.1026,  0.0304,  0.0304,  ...,  0.0304,  0.0304,  0.0688],\n",
       "          [ 0.1363,  0.0782,  0.0782,  ...,  0.0782,  0.0782,  0.1013]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[-0.0019, -0.0020, -0.0020,  ..., -0.0020, -0.0020, -0.0023],\n",
       "          [-0.0019, -0.0020, -0.0020,  ..., -0.0020, -0.0020, -0.0024],\n",
       "          [-0.0019, -0.0020, -0.0020,  ..., -0.0020, -0.0020, -0.0024],\n",
       "          ...,\n",
       "          [-0.0019, -0.0020, -0.0020,  ..., -0.0020, -0.0020, -0.0024],\n",
       "          [-0.0019, -0.0020, -0.0020,  ..., -0.0020, -0.0020, -0.0024],\n",
       "          [-0.0023, -0.0022, -0.0022,  ..., -0.0022, -0.0022, -0.0025]],\n",
       "\n",
       "         [[-0.0211, -0.0428, -0.0428,  ..., -0.0428, -0.0428, -0.0485],\n",
       "          [-0.0358, -0.0645, -0.0645,  ..., -0.0645, -0.0645, -0.0757],\n",
       "          [-0.0358, -0.0645, -0.0645,  ..., -0.0645, -0.0645, -0.0757],\n",
       "          ...,\n",
       "          [-0.0358, -0.0645, -0.0645,  ..., -0.0645, -0.0645, -0.0757],\n",
       "          [-0.0358, -0.0645, -0.0645,  ..., -0.0645, -0.0645, -0.0757],\n",
       "          [-0.0533, -0.0868, -0.0868,  ..., -0.0868, -0.0868, -0.0921]],\n",
       "\n",
       "         [[-0.0700, -0.0898, -0.0898,  ..., -0.0898, -0.0898, -0.1056],\n",
       "          [-0.0527, -0.0528, -0.0528,  ..., -0.0528, -0.0528, -0.0699],\n",
       "          [-0.0527, -0.0528, -0.0528,  ..., -0.0528, -0.0528, -0.0699],\n",
       "          ...,\n",
       "          [-0.0527, -0.0528, -0.0528,  ..., -0.0528, -0.0528, -0.0699],\n",
       "          [-0.0527, -0.0528, -0.0528,  ..., -0.0528, -0.0528, -0.0699],\n",
       "          [-0.0391, -0.0383, -0.0383,  ..., -0.0383, -0.0383, -0.0455]]]],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1707fb1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
